{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconnaissance_vocale.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKppNrKmlPJdtlZObIJjsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choarauc/form/blob/main/Reconnaissance_vocale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation et lecture d'un fichier audio\n",
        "Concepts fondamentaux : Fréquence d'échantillonnage, Spectrogramme, échelle mel ...\n",
        "Augmentation de données\n",
        "Parallèle avec la reconnaissance de l'écriture manuscrite.\n",
        "Fonction de coût : Connectionist Temporal Classification (CTC)`\n",
        "Architecture du modèle\n",
        "Décodeur : Best path decoding et Beam search decoder\n",
        "Première évalation du modèle\n",
        "Modèle de langage."
      ],
      "metadata": {
        "id": "KMC7KqyTHWBH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6FT8CfIHP-z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"libriSpeech.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Charger le premier fichier audio de df à l'aide de la fonction load_audio, et stocker le tableau de données et la fréquence d'échantillonnage sous le nom respectif audio et fe."
      ],
      "metadata": {
        "id": "PmLlTKMJHk9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "def load_audio(audio_path):\n",
        "    return librosa.load(audio_path, sr=None)\n",
        "audio, fe = load_audio(df.iloc[0,0])"
      ],
      "metadata": {
        "id": "Z9saYVjcHfVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ecouter le fichier audio en utilisant la fonction Audio."
      ],
      "metadata": {
        "id": "eITvlImnHoLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio, rate=fe)"
      ],
      "metadata": {
        "id": "ov2QbkbkHqZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  transcription de ce fichier audio.\n",
        "\n",
        "df.iloc[0,1]"
      ],
      "metadata": {
        "id": "zVQITvJPHt5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fréquence d'échantillonnage\n",
        "\n",
        "Afficher le signal audio à l'aide de la fonction plot_audio."
      ],
      "metadata": {
        "id": "MxcCzc10HyCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_audio(audio_data, fe):\n",
        "    # Intervalle de temps entre deux points.\n",
        "    dt= 1/fe \n",
        "    # Variable de temps en seconde.\n",
        "    t = dt*np.arange(len(audio_data)) \n",
        "    plt.plot(t, audio_data)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plot_audio(audio, fe)"
      ],
      "metadata": {
        "id": "mOo7sxodHz_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " observer les phénomènes d'intermodulation (fréquence d'échantillonnage trop faible).\n",
        "\n",
        " NB : Le Théorème de Shanon énonce qu'un échantillonnage à la fréquence d'échantillonnage  fefe  ne peut transmettre sans perte d'information que des fréquences inférieures à  Fe2Fe2 . Plus simplement, la fréquence d'échantillonnage  fefe  doit être au moins deux fois plus importante que la fréquence maximale du signal analogique."
      ],
      "metadata": {
        "id": "I11TMpc8H3vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import interactive\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "def sampling(fe):\n",
        "    duration = 1 # Durée du signal\n",
        "    f = 3 # Fréquence du signal\n",
        "    t_real = duration/10000*np.arange(10000) # On utilisera une fréquence d'échantillonnage très importante pour simuler le signal analogique\n",
        "    real_fonction = np.sin(2*np.pi*f*t_real)\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(t_real, real_fonction, label='Signal Analogique')\n",
        "    \n",
        "    t_s = duration/(fe-1)*np.arange(fe)\n",
        "    sampling_fonction = np.sin(2*np.pi*f*t_s)\n",
        "    # Plot the black line\n",
        "    for i in range(len(t_s)):\n",
        "        plt.plot([t_s[i], t_s[i]], [0, sampling_fonction[i]], '-k')\n",
        "        \n",
        "    plt.plot([-0, 1], [0, 0], '-k', alpha=0.5, linewidth=0.5)\n",
        "    plt.plot(t_s, sampling_fonction,'r-o', label='Signal Numérique')\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.xlim([-0.05, 1.05])\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.legend()\n",
        "    \n",
        "interactive_plot = interactive(sampling, fe=(2, 50))\n",
        "\n",
        "interactive_plot"
      ],
      "metadata": {
        "id": "Nl8g-aQ4H1Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Représentation fréquentielle (ou spectrale)\n",
        "\n",
        "\n",
        "variable  y=sin(2πfla⋅t)y=sin⁡(2πfla⋅t)  pour une fréquence d'échantillonnage de 16000 Hz et d'une durée de 2 seconde.\n",
        "\n",
        "Écouter l'enregistrement y à l'aide de la fonction Audio."
      ],
      "metadata": {
        "id": "zJJfgETZIAMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fe = 16000 # Hz\n",
        "f_la = 440 # Hz\n",
        "t = 1/fe*np.arange(2*fe) # Time\n",
        "y = np.sin(2*np.pi*f_la*t) # Audio Amplitude\n",
        "Audio(y, rate=fe)"
      ],
      "metadata": {
        "id": "YwnmZHU9IFYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " observer le signal temporel de la fonction ci-dessous et sa représentation fréquentielle.\n",
        "f(t)=sin(2πf1t)+sin(2πf2t)\n",
        "f(t)=sin⁡(2πf1t)+sin⁡(2πf2t)\n",
        " \n",
        "   L'amplitude observée dans la figure suivante est  |s(n)||s(n)| ."
      ],
      "metadata": {
        "id": "0__n84NnIOj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(f1, f2):\n",
        "    duration = 0.05 # seconde\n",
        "    fe = 8000\n",
        "    dt = 1/fe\n",
        "    t = dt*np.arange(fe*duration)\n",
        "    y = np.sin(2*np.pi*f1*t) + np.sin(2*np.pi*f2*t)# sin(w*t)\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(121)\n",
        "    plot_audio(y, fe)\n",
        "    plt.title(\"Temporal signal\")\n",
        "    plt.subplot(122)\n",
        "    y_fourier = np.abs(np.fft.fft(y))[:len(y)//2]\n",
        "    plt.bar(fe/(2*len(y_fourier))*np.arange(len(y_fourier)),y_fourier, edgecolor='b')\n",
        "    plt.title(\"Frequency signal\")\n",
        "    plt.xlabel(\"Frequency (Hz)\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    \n",
        "interactive_plot = interactive(sampling, f1=(100, 2000,100), f2=(100, 2000,100))\n",
        "interactive_plot"
      ],
      "metadata": {
        "id": "PqUTptpdIQjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Représentation tridimensionnelle : Spectrogramme. "
      ],
      "metadata": {
        "id": "Q5vbPZOgIWEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  fonction plot_spectrogram, afficher le spectrogramme de notre fichier audio avec une fréquence d'échantillonnage fe.\n",
        "\n",
        "import librosa\n",
        "import seaborn as sns\n",
        "\n",
        "def spectrogram(audio, fe, dt):\n",
        "    return np.abs(librosa.stft(audio,\n",
        "                        n_fft = int(dt*fe),\n",
        "                        hop_length = int(dt*fe/2)\n",
        "                        )\n",
        "                 )\n",
        "\n",
        "def plot_spectrogram(audio, fe, dt=0.02):\n",
        "    im = spectrogram(audio, fe, dt)\n",
        "    sns.heatmap(np.rot90(im.T), cmap='inferno', vmin=0, vmax=np.max(im)/3)\n",
        "    loc, labels = plt.xticks()\n",
        "    l = np.round((loc-loc.min())*len(audio)/fe/loc.max(), 2)\n",
        "    plt.xticks(loc, l)\n",
        "    loc, labels = plt.yticks()\n",
        "    l = np.array(loc[::-1]*fe/2/loc.max(), dtype=int)\n",
        "    plt.yticks(loc, l)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Frequency (Hz)\")\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plot_spectrogram(audio, fe)"
      ],
      "metadata": {
        "id": "f6fpo0fPIW_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# observer le signal temporel d'équation ci-dessous et son spectrogramme.\n",
        "f(t)=tsin(2πf1t)+t2sin(2πf2t)\n",
        "f(t)=tsin⁡(2πf1t)+t2sin⁡(2πf2t)"
      ],
      "metadata": {
        "id": "zydrAo2vIgma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(f1, f2, dt):\n",
        "    fe = 16000\n",
        "    duration = 0.25 #seconde\n",
        "    t = np.arange(fe*duration)/fe\n",
        "    y = t*np.sin(2*np.pi*f1*t) + t**2*np.sin(2*np.pi*f2*t)# sin(w*t)\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(121)\n",
        "    plot_audio(y, fe)\n",
        "    for i in range(int(duration//dt)+1):\n",
        "        plt.axvline(x=i*dt, color='r', linestyle='-')\n",
        "    plt.subplot(122)\n",
        "    plot_spectrogram(y, fe, dt=dt)\n",
        "    \n",
        "interactive_plot = interactive(sampling, f1=(100, 2000, 100), f2=(100, 500, 100), dt=(0.02,0.10,0.01))\n",
        "\n",
        "interactive_plot"
      ],
      "metadata": {
        "id": "IB_wGZI-Ie1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "observer le signal temporel de notre fichier audio et son spectrogramme."
      ],
      "metadata": {
        "id": "vohdC7TcIkkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(dt):\n",
        "    duration = len(audio)/fe\n",
        "    t = np.arange(fe*duration)/fe\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(121)\n",
        "    plot_audio(audio, fe)\n",
        "    for i in range(int(duration//dt)+1):\n",
        "        plt.axvline(x=i*dt, color='r', linestyle='-')\n",
        "    plt.subplot(122)\n",
        "    plot_spectrogram(audio, fe, dt=dt)\n",
        "    \n",
        "interactive_plot = interactive(sampling, dt=(0.01,0.10,0.01))\n",
        "\n",
        "interactive_plot"
      ],
      "metadata": {
        "id": "vEute8A5Imxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LogMelSpectrogram\n",
        "La perception auditive n'est pas la même pour une variation fréquentielle dans les basses fréquences par rapport aux hautes fréquences. L'échelle de Mel est une échelle de fréquences conçue pour qu'une variation constante dans le domaine des mels soit perçue comme une variation constante de fréquence (en Hz) par les auditeurs.\n",
        "\n",
        "Prenons par exemple une fréquence de base de 1000Hz. Un son à 2000Hz ne sera pas perçu par un auditeur comme étant 2 fois supérieur à la fréquence de base.\n",
        "\n",
        "Par contre, si on effectue le changement fréquentiel dans le domaine des mels, 1000Hz correspondent à 1000mels. Un son à 2000 mels, c'est-à-dire à 3428Hz, sera perçu comme étant deux fois plus aigu qu'un son à 1000Hz.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "afficher le log du spectrogramme dans l'échelle mel."
      ],
      "metadata": {
        "id": "YUVJ-gtIIoo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'n_fft': 160*16,\n",
        "    'frame_step': 160*8,\n",
        "    'lower_edge_hertz': 0,\n",
        "    'upper_edge_hertz': 8000,\n",
        "    'num_mel_bins': 160\n",
        "}\n",
        "\n",
        "def logMelSpectrogram(audio, params, fe):\n",
        "\n",
        "    stfts = librosa.stft(audio,\n",
        "                        n_fft = int(params['n_fft']),\n",
        "                        hop_length = int(params[\"frame_step\"]),\n",
        "                        center = False\n",
        "                        ).T\n",
        "    power_spectrograms = np.real(stfts * np.conj(stfts))\n",
        "\n",
        "\n",
        "    linear_to_mel_weight_matrix = librosa.filters.mel(\n",
        "                                sr=fe,\n",
        "                                n_fft=int(params['n_fft']) + 1,\n",
        "                                n_mels=params['num_mel_bins'],\n",
        "                                fmin=params['lower_edge_hertz'],\n",
        "                                fmax=params['upper_edge_hertz']\n",
        "                    ).T\n",
        "\n",
        "    mel_spectrograms = np.tensordot(\n",
        "                power_spectrograms,\n",
        "                linear_to_mel_weight_matrix,\n",
        "                1\n",
        "            )\n",
        "\n",
        "    return (np.log(mel_spectrograms + 1e-8).astype(np.float16))\n",
        "\n",
        "\n",
        "def plot_logMelSpectrogram(audio, params, fe):\n",
        "    sns.heatmap(np.rot90(logMelSpectrogram(audio, params, fe)), cmap='inferno', vmin = -6)\n",
        "    loc, labels = plt.xticks()\n",
        "    l = np.round((loc-loc.min())*len(audio)/fe/loc.max(), 2)\n",
        "    plt.xticks(loc, l)\n",
        "    plt.yticks([])\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Frequency (Mel)\")\n",
        "    \n",
        "    \n",
        "plt.figure(figsize=(20,5))\n",
        "plot_logMelSpectrogram(audio, params, fe)"
      ],
      "metadata": {
        "id": "_Hj3FWx4Ityx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Influence du bruit sur un signal\n",
        "Le bruit est un son indésirable perçu comme un grésillement. Il n'apporte aucune information supplémentaire et sa présence peut impacter la performance des systèmes de traitement de signal. Par ailleurs, la forme du bruit d'acquisition n'est pas la même selon récepteur.\n",
        "\n",
        "En général, le signal indésirable est modélisé par un bruit blanc (distribution gaussienne) :\n",
        "X∼(μ,σ2)\n",
        "X∼N(μ,σ2)\n",
        " \n",
        "P(x)=1σ2π⎯⎯⎯⎯√e−(x−μ)2/2σ2\n",
        "P(x)=1σ2πe−(x−μ)2/2σ2\n",
        " "
      ],
      "metadata": {
        "id": "tuQNXuavIx79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir un vecteur aléatoire de 5000 valeurs suivant la loi  X∼(0,1)X∼N(0,1)  à l'aide de la fonction normal de numpy.random.\n",
        "\n",
        "# Afficher la courbe du vecteur aléatoire à l'aide de la fonction plot_audio et on choisira une fréquence d'échantillonnage de 8000.\n",
        "\n",
        "# Afficher la densité du vecteur aléatoire."
      ],
      "metadata": {
        "id": "Auo1ST2fI1ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_audio = np.random.normal(0,1,5000) # noise signal\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121)\n",
        "plt.title('Audio Signal')\n",
        "plot_audio(noise_audio, fe) # plot noise signal\n",
        "plt.subplot(122)\n",
        "plt.title('Density')\n",
        "plt.xlabel('Amplitude')\n",
        "plt.ylabel('Density probabilité')\n",
        "sns.distplot(noise_audio) # plot distribution of signal\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "HdhIfl4vI5pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "afficher l'influence du bruit sur le signal et le spectrogramme."
      ],
      "metadata": {
        "id": "h5sGSOgZI-Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_noise(audio, rate):\n",
        "    noises = np.random.normal(0,np.max(np.abs(audio))*rate, len(audio))\n",
        "    return np.array(audio + noises)\n",
        "\n",
        "# Audio file 0\n",
        "audio, fe = load_audio(df.audio_path[0])\n",
        "audio_noise = random_noise(audio, rate=0.05)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Audio\")\n",
        "plot_audio(audio, fe)\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"Spectre audio\")\n",
        "plot_logMelSpectrogram(audio, params, fe)\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Audio with noise\")\n",
        "plot_audio(audio_noise, fe)\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(\"Spectre with noise\")\n",
        "plot_logMelSpectrogram(audio_noise, params, fe)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "d3X4nlDpI9rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "écouter le signal bruité."
      ],
      "metadata": {
        "id": "Argmnh1SJDfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Noise signal\")\n",
        "Audio(audio_noise, rate=fe)\n",
        "# print(\"Real signal\")\n",
        "# Audio(audio, rate=fe)"
      ],
      "metadata": {
        "id": "ISsbDX3EJD5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation de données\n",
        "\n",
        "Pour eviter le sur-apprentissage \n",
        "\n",
        "Étirement du temps à l'aide de la fonction time_stretch de librosa.effects.\n",
        "\n",
        "Décalage temporel aléatoire à l'aide de la fonction pad de numpy.\n",
        "\n",
        "Appliquer des bruits en superposant nos fichiers audio avec des bruits enregistrés (ou à un bruit blanc)."
      ],
      "metadata": {
        "id": "MTmBbn0QJIBZ"
      }
    }
  ]
}