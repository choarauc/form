{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoundingBox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOr0DWw3aFK2ssD5BXBKPQU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choarauc/form/blob/main/BoundingBox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA6UjnoewPt2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('face_images.csv')\n",
        "df.insert(1, 'p', 1)\n",
        "df.insert(2, 'xmoy', (df.xmax + df.xmin)/2)\n",
        "df.insert(3, 'ymoy', (df.ymax + df.ymin)/2)\n",
        "df.insert(4, 'w', (df.xmax - df.xmin))\n",
        "df.insert(5, 'h', (df.ymax - df.ymin))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " fonctions load_image et show_bounding_box."
      ],
      "metadata": {
        "id": "zvprknXSwZGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "folder_images = 'images/'\n",
        "\n",
        "@tf.function\n",
        "def load_image(filepath, resize=None):\n",
        "    im = tf.io.read_file(folder_images + filepath)\n",
        "    im = tf.image.decode_png(im, channels=3)\n",
        "    if resize:\n",
        "        return tf.image.resize(im, resize)\n",
        "    else :\n",
        "        return im\n",
        "\n",
        "\n",
        "def show_bounding_box(im, bbox, normalised=True, color='r'):\n",
        "    # Signification de bbox\n",
        "    x, y, w, h = bbox\n",
        "    # Convertir les cordonées (x,y,w,h) en (x1,x2,y1,y2)\n",
        "    x1=x-w/2\n",
        "    x2=x+w/2\n",
        "    y1=y-h/2\n",
        "    y2=y+h/2\n",
        "    \n",
        "    # redimensionner en cas de normalisation\n",
        "    if normalised:\n",
        "        x1=x1*im.shape[1]\n",
        "        x2=x2*im.shape[1]\n",
        "        y1=y1*im.shape[0]\n",
        "        y2=y2*im.shape[0]\n",
        "        \n",
        "    # Afficher l'image\n",
        "    plt.imshow(im)\n",
        "    \n",
        "    # Afficher la bounding box\n",
        "    plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1],\"r\")\n",
        "        \n",
        "im = load_image(df.filename[0])\n",
        "\n",
        "bbox = df[['xmoy', 'ymoy', 'w', 'h']].values[0]\n",
        "# Afficher l'image ainsi que la bounding box\n",
        "show_bounding_box(im, bbox)"
      ],
      "metadata": {
        "id": "gHfYMvPLwZlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx=1\n",
        "\n",
        "im = load_image(df.filename[idx])\n",
        "plt.imshow(im)\n",
        "liste_colonns = ['x'+str(i) for i in range(68)] + ['y'+str(i) for i in range(68)]\n",
        "landmarks = df[liste_colonns].values[idx]\n",
        "plt.plot(landmarks[:68]*im.shape[1],landmarks[68:]*im.shape[0], '.',color='red')"
      ],
      "metadata": {
        "id": "IgTja02awhBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution des valeurs\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kRRlFcgtwkGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.displot(df.x0)\n",
        "plt.show()\n",
        "sns.displot(df.y0)\n",
        "plt.show()\n",
        "sns.displot(df.x33)\n",
        "plt.show()\n",
        "sns.displot(df.y33)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bPN6UXfwlm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generer des images sans visage"
      ],
      "metadata": {
        "id": "vXlVLQT5wpsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Return all path in folder iccv09Data with .jpg extention\n",
        "backgrounds_dir = './iccv09Data/'\n",
        "background_image_files = glob(backgrounds_dir+'**.jpg')\n",
        "\n",
        "background_image = []\n",
        "for p in tqdm(background_image_files):\n",
        "    img = plt.imread(p)\n",
        "    background_image.append(img)\n",
        "\n",
        "len(background_image)\n",
        "\n",
        "\n",
        "def random_crop(img, WINDOW_SIZE):\n",
        "    max_allowed_size = np.min(img.shape[:2])\n",
        "    if WINDOW_SIZE>max_allowed_size:\n",
        "        return random_crop(img, int(WINDOW_SIZE/1.5))\n",
        "    else :\n",
        "        size = np.random.randint(WINDOW_SIZE, max_allowed_size)\n",
        "    max_width = img.shape[0] - size - 1\n",
        "    max_height = img.shape[1] - size - 1\n",
        "    left = 0 if (max_width <= 1)  else np.random.randint(0, max_width)\n",
        "    top  = 0 if (max_height <= 1) else np.random.randint(0, max_height)\n",
        "    return img[left:left+size,top:top+size]\n",
        "\n",
        "def open_background(img: str, resize=(256,256), WINDOW_SIZE: int=150):\n",
        "    img = random_crop(img, WINDOW_SIZE)\n",
        "    if resize:\n",
        "        img = cv2.resize(img, resize)\n",
        "    return img\n",
        "\n",
        "import random\n",
        "def sample_data(n: int):\n",
        "    xs = [open_background(f, WINDOW_SIZE=70) for f in np.random.choice(background_image, n, replace=True)]\n",
        "    ys = np.zeros([n, y_train.shape[1]])\n",
        "    return np.array(xs), ys"
      ],
      "metadata": {
        "id": "UyKNL62vwm-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Séparer le jeu de données df.filepath et les variables cibles en un ensemble d'entraînement X_train_path, y_train, et en un ensemble de test X_test_path, y_test."
      ],
      "metadata": {
        "id": "GSQ-asE7wuDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "X_train_path, X_test_path, y_train, y_test = train_test_split(df.filename, df.drop(['filename', 'xmin', 'xmax', 'ymin', 'ymax'], axis=1), train_size=0.95, random_state=1234)\n",
        "\n",
        "# X_test = []\n",
        "# for p in tqdm(X_test_path):\n",
        "#     im = plt.imread(p)\n",
        "#     if (im.shape==2):\n",
        "#         im = np.expand_dims(im, axis=-1)\n",
        "#         im = np.concatenate([im, im, im], axis=-1)\n",
        "#     im = im*255\n",
        "#     im = im[...,[0,1,2]].astype(np.uint8)\n",
        "#     X_test.append(cv2.resize(im, (256,256)))\n",
        "    \n",
        "# X_test = np.array(X_test)"
      ],
      "metadata": {
        "id": "P0LXkbrkwvuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset tensorflow permettant de charger les images d'entraînement en mémoires."
      ],
      "metadata": {
        "id": "E2Zb3S51wy0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "ratio = 1/2\n",
        "\n",
        "def load_image(filepath, y, resize=(256,256)):\n",
        "    im = tf.io.read_file(folder_images + filepath)\n",
        "    im = tf.image.decode_png(im, channels=3)\n",
        "#     im_shape = tf.shape(im)\n",
        "    im = tf.image.resize(im, resize)\n",
        "    tx_max = 256*tf.nn.relu(y[1]-y[3]/2)\n",
        "    tx_min = -256*tf.nn.relu(1-y[1]-y[3]/2)\n",
        "    ty_max = 256*tf.nn.relu(y[2]-y[4]/2)\n",
        "    ty_min = -256*tf.nn.relu(1-y[2]-y[4]/2)\n",
        "    tx = np.random.uniform(tx_min, tx_max)\n",
        "    ty = np.random.uniform(ty_min, ty_max)\n",
        "    im = tf.keras.preprocessing.image.apply_affine_transform(\n",
        "    im.numpy(), theta=0, tx=ty, ty=tx, shear=0, zx=1, zy=1, row_axis=0, col_axis=1,\n",
        "    channel_axis=2, fill_mode='nearest', cval=0.0, order=1\n",
        ")\n",
        "    y_new = y.numpy().copy()\n",
        "    y_new[1] += -tx/256\n",
        "    y_new[2] += -ty/256\n",
        "    y_new[5:5+68] += -tx/256\n",
        "    y_new[5+68:] += -ty/256\n",
        "    \n",
        "    return im, y_new\n",
        "\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
        "\n",
        "dataset_train = dataset_train.shuffle(100000).map(\n",
        "    lambda x, y : tf.py_function(\n",
        "        load_image,\n",
        "        [x, y],\n",
        "        [tf.float32, tf.float32]\n",
        "    ),\n",
        "    num_parallel_calls=-1).\n",
        "batch(int(batch_size * ratio))"
      ],
      "metadata": {
        "id": "O77OhRk6w0Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#afficher les premieres images "
      ],
      "metadata": {
        "id": "2qqed6O0w2pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = X_train_path.values[1]\n",
        "bbox = y_train.values[1]\n",
        "img, y = tf.py_function(load_image, [filepath, bbox], [tf.float32, tf.float32])\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121)\n",
        "show_bounding_box(img.numpy().astype(int), y[1:5])\n",
        "landmarks = y[5:]\n",
        "plt.plot(landmarks[:68]*img.shape[1],landmarks[68:]*img.shape[0], '.',color='red')"
      ],
      "metadata": {
        "id": "4nYGQmqkw4mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generateur de batchs avec ou sans objet"
      ],
      "metadata": {
        "id": "mYOlBYm9w77n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(X, y, batch_size, ratio=0.5):\n",
        "    batch_face = int(batch_size*ratio)\n",
        "    while(True):\n",
        "        iterator_img = iter(dataset_train)\n",
        "        for i in range(0, len(X)-batch_face, batch_face):\n",
        "            data_X, data_Y = next(iterator_img)\n",
        "            noobject, y_nooboject = sample_data(batch_size-batch_face)\n",
        "            data_X = np.concatenate([data_X, noobject], axis=0)\n",
        "            data_Y = np.concatenate([data_Y, y_nooboject], axis=0)\n",
        "            yield data_X, data_Y\n",
        "            \n",
        "gen = generator(X_train_path, y_train, batch_size, ratio=ratio)"
      ],
      "metadata": {
        "id": "uSp0Srdfw6o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Définition du modèle de détection d'objet."
      ],
      "metadata": {
        "id": "eEyFzKYpxBgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "\n",
        "# Load the model efficientNet\n",
        "efficientNet = EfficientNetB0(include_top=False, input_shape=(256,256,3))\n",
        "\n",
        "# Freeze the blackbone\n",
        "for layer in efficientNet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "input_model = Input(shape=[256,256,3])\n",
        "feature = efficientNet(input_model)\n",
        "x = GlobalAveragePooling2D()(feature)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "regression = Dense(4, activation='linear')(x)\n",
        "object_prob = Dense(1, activation='sigmoid')(x)\n",
        "key_points = Dense(68*2, activation='linear')(x)\n",
        "output_model = tf.concat([object_prob, regression, key_points], axis=-1)\n",
        "\n",
        "model = Model(inputs=input_model, outputs=output_model)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BGm8mUe9xB39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonction de perte"
      ],
      "metadata": {
        "id": "5DV0xzmMxE2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_landmarks = 10\n",
        "lambda_regression = 100\n",
        "lambda_classification = 1\n",
        "\n",
        "def loss_landmarks(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
        "\n",
        "def loss_regression(y_true, y_pred):\n",
        "    return (tf.square(y_true[:,0]-y_pred[:,0]) + tf.square(y_true[:,1]-y_pred[:,1]) + tf.square(tf.sqrt(tf.abs(y_true[:,2])) - tf.sqrt(tf.abs(y_pred[:,2]))) + tf.square(tf.sqrt(tf.abs(y_true[:,3])) - tf.sqrt(tf.abs(y_pred[:,3]))))\n",
        "\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    return lambda_regression*y_true[:,0]*loss_regression(y_true[:,1:5], y_pred[:,1:5]) + lambda_landmarks*y_true[:,0]*loss_landmarks(y_true[:,5:], y_pred[:,5:]) + lambda_classification*tf.keras.losses.BinaryCrossentropy()(y_true[:,0], y_pred[:,0])\n",
        "\n",
        "model.compile(loss= loss_function, optimizer='adam')"
      ],
      "metadata": {
        "id": "OnIO6hAZxGke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(gen, steps_per_epoch=int(len(X_train_path)/(batch_size*ratio)), epochs=10)# , validation_data=(X_test, y_test)"
      ],
      "metadata": {
        "id": "46msH6L9xJVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2, urllib, json\n",
        "\n",
        "def show_img(img, model):\n",
        "    plt.imshow(img/255)\n",
        "    t0=time.time()\n",
        "    prediction = model.predict(np.array([img], dtype=np.float32))[0]\n",
        "    p, x0, y0, w0, h0 = prediction[:5]\n",
        "    landmarks = prediction[5:]\n",
        "    plt.plot(landmarks[:68]*img.shape[1],landmarks[68:]*img.shape[0], '.',color='red')\n",
        "    print(x0, y0, w0, h0)\n",
        "    print(\"Execution time :\",time.time()-t0,\"secondes\")\n",
        "    print('Probability :', p)\n",
        "    x1= (x0-w0/2)*img.shape[1]\n",
        "    x2= (x0+w0/2)*img.shape[1]\n",
        "    y1= (y0-h0/2)*img.shape[0]\n",
        "    y2= (y0+h0/2)*img.shape[0]\n",
        "    plt.plot([x1,x2,x2,x1,x1], [y1,y1,y2,y2,y1], \"r\")\n",
        "    plt.show()\n",
        "    \n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url) \n",
        "    img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    img = cv2.imdecode(img, -1)\n",
        "    img = cv2.resize(img, (256,256))\n",
        "    img = img[..., [2,1,0]]\n",
        "    return tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "\n",
        "## Example :\n",
        "img = url_to_image(\"https://images.sudouest.fr/2020/10/02/5f7729c066a4bd5078d0c6dd/golden/1200x750/donald-trump-a-annonce.jpg\")\n",
        "show_img(img , model)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SvY3FwUBxJuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test de webcam"
      ],
      "metadata": {
        "id": "NKMalKZMxNXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from IPython.display import HTML\n",
        "from PIL import Image\n",
        "import base64, io\n",
        "import numpy as np\n",
        "\n",
        "main_text = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "    canvas {\n",
        "        display: none;\n",
        "    }\n",
        "    </style>\n",
        "\n",
        "<video id=\"video\" width=\"320\" height=\"240\" autoplay></video>\n",
        "<button id=\"snap\">Snap Photo</button>\n",
        "<canvas id=\"canvas\" width=\"320\" height=\"240\"></canvas>\n",
        "\n",
        "<script>\n",
        "// Grab elements, create settings, etc.\n",
        "var video = document.getElementById('video');\n",
        "\n",
        "// Get access to the camera!\n",
        "if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "    // Not adding `{ audio: true }` since we only want video now\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {\n",
        "        //video.src = window.URL.createObjectURL(stream);\n",
        "        //video.play();\n",
        "        video.srcObject=stream;\n",
        "        video.play();\n",
        "    });\n",
        "}\n",
        "\n",
        "// Elements for taking the snapshot\n",
        "var canvas = document.getElementById('canvas');\n",
        "var context = canvas.getContext('2d');\n",
        "var video = document.getElementById('video');\n",
        "var image = canvas.toDataURL(\"image/png\");\n",
        "IPython.notebook.kernel.execute(\"image = '\" + image + \"'\")\n",
        "\n",
        "// Trigger photo take\n",
        "document.getElementById(\"snap\").addEventListener(\"click\", function() {\n",
        "\tcontext.drawImage(video, 0, 0, 320, 240);\n",
        "    var myCanvas = document.getElementById('canvas');\n",
        "    var image = myCanvas.toDataURL(\"image/png\");\n",
        "    IPython.notebook.kernel.execute(\"print('testing')\")\n",
        "    IPython.notebook.kernel.execute(\"imageWebCam = '\" + image + \"'\")\n",
        "});\n",
        "</script>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def show_bboxes_webcam(model):\n",
        "    img = np.array(Image.open(io.BytesIO(base64.b64decode(imageWebCam.split(',')[1]))))[:,:,0:3]\n",
        "    img = tf.image.resize(img, (256,256))\n",
        "    show_img(img, model)\n",
        "    \n",
        "HTML(main_text)"
      ],
      "metadata": {
        "id": "z-JeCSQDxOxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois le boutton \"Snap Photo\" pressé, exécuter la cellule suivante.\n"
      ],
      "metadata": {
        "id": "BszvPjhNxRzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_bboxes_webcam(model)"
      ],
      "metadata": {
        "id": "E562gF7pxTWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test sur camera"
      ],
      "metadata": {
        "id": "Xw8tkL6IxW9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# To capture video from webcam. \n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "\n",
        "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
        "bottomLeftCornerOfText = (10,500)\n",
        "fontScale              = 1\n",
        "fontColor              = (0,255,0)\n",
        "lineType               = 2\n",
        "\n",
        "\n",
        "while True:\n",
        "    \n",
        "    try :\n",
        "        # Read the frame\n",
        "        _, img = cap.read()\n",
        "        img = img\n",
        "\n",
        "        img_resized = cv2.resize(img, (256, 256))\n",
        "\n",
        "        prediction = model(np.array([img_resized[:,:,[2,1,0]]], dtype=np.float32))[0]\n",
        "        obj, x_m, y_m, w, h = prediction[:5]\n",
        "        landmarks = prediction[5:]\n",
        "        point_x = landmarks[:68]*img.shape[1]\n",
        "        point_y = landmarks[68:]*img.shape[0]\n",
        "        for i in range(68):\n",
        "            cv2.circle(img, (point_x[i],point_y[i]), radius=0, color=(0, 255, 0), thickness=3)\n",
        "        x_m = (x_m * img.shape[1]).numpy()\n",
        "        y_m = (y_m * img.shape[0]).numpy()\n",
        "        w = (tf.abs(w) * img.shape[1]).numpy()\n",
        "        h = (h * img.shape[0]).numpy()\n",
        "        # Draw the rectangle around each face\n",
        "        cv2.rectangle(img, (int(x_m-w/2), int(y_m-h/2)), (int(x_m+w/2), int(y_m+h/2)), (0, 255, 0), 2)\n",
        "        cv2.putText(img, str(obj.numpy()), \n",
        "                        (int(x_m-w/2), int(y_m-h/2)+30), \n",
        "                        font, \n",
        "                        fontScale,\n",
        "                        fontColor,\n",
        "                        lineType)\n",
        "\n",
        "        # Display\n",
        "        cv2.imshow('img', img)\n",
        "        # Stop if escape key is pressed\n",
        "        k = cv2.waitKey(30) & 0xff\n",
        "        if k==27:\n",
        "            break\n",
        "    except :\n",
        "        break\n",
        "# Release the VideoCapture object\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "s1K0bmalxYCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}