{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_YOLO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsw0XiHkOhQ6s151fELFgT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choarauc/form/blob/main/DL_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " définir notre modèle pour une grille de taille 8x8."
      ],
      "metadata": {
        "id": "dTQS7XX4Mnc8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLpmDwwcMjk9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, LeakyReLU, Dropout, Reshape, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "nb_class = 0\n",
        "\n",
        "# Backbone\n",
        "efficientNet = EfficientNetB0(include_top=False, input_shape=(256,256,3))\n",
        "\n",
        "# Freeze the blackbone\n",
        "for layer in efficientNet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Définition de la partie encoder\n",
        "model = Sequential()\n",
        "# Feature extration part\n",
        "model.add(efficientNet) \n",
        "model.add(Reshape([-1, 1280]))\n",
        "# Regression Part\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5 + nb_class))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prédiction"
      ],
      "metadata": {
        "id": "CtyfWZZWMsMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "onction convertissant la sortie du modèle en coordonnées (x,y,w,h)"
      ],
      "metadata": {
        "id": "OnYTCYV2MuiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_netout(y_pred_raw):\n",
        "    y_pred_xy = (tf.nn.tanh(y_pred_raw[..., 1:3]))\n",
        "    y_pred_wh = tf.sigmoid(y_pred_raw[..., 3:5])\n",
        "    y_pred_conf = tf.sigmoid(y_pred_raw[..., :1])\n",
        "    return tf.concat([y_pred_conf, y_pred_xy, y_pred_wh], -1)"
      ],
      "metadata": {
        "id": "6RYhUIHMMu__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET"
      ],
      "metadata": {
        "id": "FBJGmwMJMy75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('face_images.csv')\n",
        "\n",
        "df['xmoy'] = (df.xmax + df.xmin)/2\n",
        "df['ymoy'] = (df.ymax + df.ymin)/2\n",
        "df['w'] = (df.xmax - df.xmin)\n",
        "df['h'] = (df.ymax - df.ymin)\n",
        "\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "7OMGvREDMxxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fonctions load_image et show_bounding_box."
      ],
      "metadata": {
        "id": "tBD9EB5WM1Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "folder_images = 'images/'\n",
        "\n",
        "@tf.function\n",
        "def load_image(filepath, resize=None):\n",
        "    im = tf.io.read_file(folder_images + filepath)\n",
        "    im = tf.image.decode_png(im, channels=3)\n",
        "    if resize:\n",
        "        return tf.image.resize(im, resize)\n",
        "    else :\n",
        "        return im\n",
        "\n",
        "\n",
        "def show_bounding_box(im, bbox, normalised=True, color='r'):\n",
        "    # Signification de bbox\n",
        "    x, y, w, h = bbox\n",
        "    # Convertir les cordonées (x,y,w,h) en (x1,x2,y1,y2)\n",
        "    x1=x-w/2\n",
        "    x2=x+w/2\n",
        "    y1=y-h/2\n",
        "    y2=y+h/2\n",
        "    \n",
        "    # redimensionner en cas de normalisation\n",
        "    if normalised:\n",
        "        x1=x1*im.shape[1]\n",
        "        x2=x2*im.shape[1]\n",
        "        y1=y1*im.shape[0]\n",
        "        y2=y2*im.shape[0]\n",
        "        \n",
        "    # Afficher l'image\n",
        "    plt.imshow(im)\n",
        "    \n",
        "    # Afficher la bounding box\n",
        "    plt.plot([x1,x2,x2,x1,x1],[y1,y1,y2,y2,y1],\"r\")\n",
        "        \n",
        "im = load_image(df.filename[0])\n",
        "\n",
        "bbox = df[['xmoy', 'ymoy', 'w', 'h']].values[0]\n",
        "# Afficher l'image ainsi que la bounding box\n",
        "show_bounding_box(im, bbox)"
      ],
      "metadata": {
        "id": "Os-XcvaIM154"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_path, X_test_path, y_train, y_test = train_test_split(df.filename.values, df[['xmoy', 'ymoy', 'w', 'h']].values, train_size=0.9, random_state=1234)\n"
      ],
      "metadata": {
        "id": "zZ-3f4zfM58h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Générateur et augmentation de données"
      ],
      "metadata": {
        "id": "MNN81BRKM8UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_image(filepath, y, resize=(256,256)):\n",
        "    # Load image\n",
        "    im = tf.io.read_file(folder_images+filepath)\n",
        "    im = tf.image.decode_png(im, channels=3)\n",
        "    # Resize image\n",
        "    im = tf.image.resize(im, resize)\n",
        "    # Find the max translation to keep the object in the image\n",
        "    tx_max = resize[1]*tf.nn.relu(y[0]-y[2]/2)\n",
        "    tx_min = -resize[1]*tf.nn.relu(1-y[0]-y[2]/2)\n",
        "    ty_max = resize[0]*tf.nn.relu(y[1]-y[3]/2)\n",
        "    ty_min = -resize[0]*tf.nn.relu(1-y[1]-y[3]/2)\n",
        "    tx = np.random.uniform(tx_min, tx_max)\n",
        "    ty = np.random.uniform(ty_min, ty_max)\n",
        "    # Apply the transformation in the image\n",
        "    im = tf.keras.preprocessing.image.apply_affine_transform(\n",
        "    im.numpy(), theta=0, tx=ty, ty=tx, shear=0, zx=1, zy=1, row_axis=0, col_axis=1,\n",
        "    channel_axis=2, fill_mode='nearest', cval=0.0, order=1\n",
        ")\n",
        "    # Correct the target variable\n",
        "    y_new = y.numpy().copy()\n",
        "    y_new[0] += -tx/resize[1]\n",
        "    y_new[1] += -ty/resize[0]\n",
        "    \n",
        "    return im, y_new\n",
        "\n"
      ],
      "metadata": {
        "id": "NUlNv29VM8t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resultat de l'augmentation \n",
        "\n",
        "\n",
        "filepath = X_train_path[1]\n",
        "bbox = y_train[1]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "for j in range(8):\n",
        "    plt.subplot(2,4,j+1)\n",
        "    img, y = tf.py_function(load_image, [filepath, bbox], [tf.float32, tf.float32])\n",
        "    show_bounding_box(img.numpy().astype(int), y)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    # plt.imshow(X_t[i].numpy().astype(int))"
      ],
      "metadata": {
        "id": "pBguxPvbNAoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable cible\n",
        "\n",
        "\n",
        "fonction convert_target."
      ],
      "metadata": {
        "id": "FxBsTpraNHIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "nb_class = 0\n",
        "output_shape = (8, 8)\n",
        "\n",
        "def convert_target(bboxes, output_shape=output_shape, nb_classes=0):\n",
        "    y_target = np.zeros([output_shape[0], output_shape[1], 1+4])# +nb_classes\n",
        "    lx=1/output_shape[1]\n",
        "    ly=1/output_shape[0]\n",
        "    for x, y, w, h in [bboxes]:\n",
        "        idx_x = int(x//lx)\n",
        "        idx_y = int(y//ly)\n",
        "        # Presence of object\n",
        "        y_target[idx_y, idx_x, 0] = 1\n",
        "        # Class of object\n",
        "        # y_target[idx_x, idx_y, 5+int(c)] = 1\n",
        "        # Coordinate x\n",
        "        y_target[idx_y, idx_x, 1] = 2*(x/lx - (idx_x+0.5))\n",
        "        # Coordinate y\n",
        "        y_target[idx_y, idx_x, 2] = 2*(y/ly - (idx_y+0.5))\n",
        "        # Coordinate w\n",
        "        y_target[idx_y, idx_x, 3] = w\n",
        "        # Coordinate h\n",
        "        y_target[idx_y, idx_x, 4] = h\n",
        "        \n",
        "    return y_target.reshape([-1, 1+4])# +nb_classes\n",
        "\n",
        "convert_target(bbox, output_shape, nb_classes=nb_class)"
      ],
      "metadata": {
        "id": "ij6Ccwd7NJRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " matrice de probabilité de présence."
      ],
      "metadata": {
        "id": "mSHbUA9FNMUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, y = tf.py_function(load_image, [filepath, bbox], [tf.float32, tf.float32])\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121)\n",
        "show_bounding_box(img.numpy().astype(int), y)\n",
        "plt.subplot(122)\n",
        "plt.imshow(convert_target(y, output_shape)[:,0].reshape(output_shape))"
      ],
      "metadata": {
        "id": "N6eES5uyNM0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definition du dataset\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def load_image(filepath, y, resize=(256,256)):\n",
        "    im = tf.io.read_file(folder_images + filepath)\n",
        "    im = tf.image.decode_png(im, channels=3)\n",
        "#     im_shape = tf.shape(im)\n",
        "    im = tf.image.resize(im, resize)\n",
        "    tx_max = 256*tf.nn.relu(y[0]-y[2]/2)\n",
        "    tx_min = -256*tf.nn.relu(1-y[0]-y[2]/2)\n",
        "    ty_max = 256*tf.nn.relu(y[1]-y[3]/2)\n",
        "    ty_min = -256*tf.nn.relu(1-y[1]-y[3]/2)\n",
        "    tx = np.random.uniform(tx_min, tx_max)\n",
        "    ty = np.random.uniform(ty_min, ty_max)\n",
        "    im = tf.keras.preprocessing.image.apply_affine_transform(\n",
        "    im.numpy(), theta=0, tx=ty, ty=tx, shear=0, zx=1, zy=1, row_axis=0, col_axis=1,\n",
        "    channel_axis=2, fill_mode='nearest', cval=0.0, order=1\n",
        ")\n",
        "    y_new = y.numpy().copy()\n",
        "    y_new[0] += -tx/256\n",
        "    y_new[1] += -ty/256\n",
        "    \n",
        "    return im, convert_target(y_new, output_shape)\n",
        "\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
        "\n",
        "dataset_train = dataset_train.shuffle(100000).map(lambda x, y : tf.py_function(load_image, [x, y], [tf.float32, tf.float32]), num_parallel_calls=-1).batch(int(batch_size))"
      ],
      "metadata": {
        "id": "gEXup9JYNPtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verif de la cohérence\n",
        "\n",
        "\n",
        "X_t, y_t = next(iter(dataset_train))\n",
        "plt.figure(figsize=(15,7))\n",
        "for j, i in enumerate(np.random.randint(0, batch_size, [4])):\n",
        "    plt.subplot(2,4,2*j+1)\n",
        "    plt.imshow(X_t[i].numpy().astype(int))\n",
        "    plt.subplot(2,4,2*j+2)\n",
        "    plt.imshow(y_t[i,:,0].numpy().reshape(output_shape))\n"
      ],
      "metadata": {
        "id": "YX-rTmnINUH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_raw = model.predict(X_t)\n",
        "\n",
        "y_pred = transform_netout(y_pred_raw)\n",
        "\n"
      ],
      "metadata": {
        "id": "7R2UrM9RNXHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonction de perte de l'algorithme\n",
        "\n",
        "implémentation de cette fonction de perte."
      ],
      "metadata": {
        "id": "O6RzQKwVNbDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_class = 20\n",
        "\n",
        "def class_loss(y_true, y_pred):\n",
        "    # Vecteur de présence d'un objet\n",
        "    y_true_conf = y_true[...,0]\n",
        "    # Probabilité conditionelle des vrais objets\n",
        "    y_true_class = tf.one_hot(y_true[...,5], nb_class)\n",
        "    # Probabilité conditionelle des prédictions\n",
        "    y_pred_class = y_pred[...,5:]\n",
        "    # Calcul de la fonction de perte\n",
        "    class_loss = tf.reduce_sum(y_true_conf*tf.reduce_sum(tf.squarre(y_true_class - y_pred_class), axis=-1), axis=-1)\n",
        "    return class_loss"
      ],
      "metadata": {
        "id": "Ht8w3GdHNd8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'erreur de localisation"
      ],
      "metadata": {
        "id": "C_jhH_pANgEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coord_loss(y_true, y_pred):\n",
        "    # Probabilty of object presence\n",
        "    y_true_conf = y_true[...,0]\n",
        "    \n",
        "    # x and y loss for real object\n",
        "    y_true_xy = y_true[...,1:3]\n",
        "    y_pred_xy = y_pred[...,1:3]\n",
        "    xy_loss = tf.reduce_sum(tf.reduce_sum(tf.square(y_true_xy - y_pred_xy),axis=-1)*y_true_conf, axis=-1)\n",
        "    \n",
        "    # w and h loss for real object\n",
        "    y_true_wh = y_true[...,3:5]\n",
        "    y_pred_wh = y_pred[...,3:5]\n",
        "    wh_loss = tf.reduce_sum(tf.reduce_sum(tf.square(tf.sqrt(y_true_wh) - tf.sqrt(y_pred_wh)), axis=-1)*y_true_conf, axis=-1)\n",
        "    return xy_loss + wh_loss\n",
        "\n",
        "# Coordinate loss for the prediction X_t\n",
        "coord_loss(y_t, y_pred)\n"
      ],
      "metadata": {
        "id": "WbPBMc-xNh4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_noobj = 0.5\n",
        "\n",
        "def object_loss(y_true, y_pred):\n",
        "    # x and y loss for real object\n",
        "    y_true_p = y_true[...,0]\n",
        "    y_pred_p = y_pred[...,0]\n",
        "    return tf.reduce_sum((lambda_noobj + (1-lambda_noobj)*y_true_p)*tf.square(y_true_p - y_pred_p), axis=-1)\n",
        "\n",
        "# Object loss for the prediction X_t\n",
        "object_loss(y_t, y_pred)\n"
      ],
      "metadata": {
        "id": "vtYNVGTNNjn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Erreur globale"
      ],
      "metadata": {
        "id": "85GRtnKeNmgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_coord = 5\n",
        "lambda_object = 1\n",
        "\n",
        "def global_loss(y_true, y_pred):\n",
        "    # Convert input\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    y_pred = transform_netout(y_pred)\n",
        "    loss_coordinate = coord_loss(y_true, y_pred)\n",
        "    loss_object = object_loss(y_true, y_pred)\n",
        "    return lambda_object*loss_object + lambda_coord*loss_coordinate\n",
        "\n",
        "# Global loss for the prediction X_t\n",
        "global_loss(y_t, y_pred)"
      ],
      "metadata": {
        "id": "Q5VM5M3wNnOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entraînement du modèle"
      ],
      "metadata": {
        "id": "cMPPRVg2Npy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "model.compile(optimizer=Adam(1e-3), loss=global_loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Save automatically the weights\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath = 'model', \n",
        "                                       monitor = 'loss',\n",
        "                                       save_best_only = True,\n",
        "                                       save_weights_only = True,\n",
        "                                       mode = 'min',\n",
        "                                       save_freq = 'epoch')\n",
        "\n",
        "# Callback to reduce automatically the learning rate.\n",
        "lr_plateau = callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
        "                                         patience=5,\n",
        "                                         factor=0.1,\n",
        "                                         verbose=2,\n",
        "                                         mode='min')\n",
        "\n",
        "model.fit(dataset_train, epochs=10, workers=-1,  callbacks = [lr_plateau, checkpoint])"
      ],
      "metadata": {
        "id": "jopo0RLlNqeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prédiction des coordonnées absolues"
      ],
      "metadata": {
        "id": "PJc4kuKQNtL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_yolo_grid(g):\n",
        "    c_x = tf.cast(tf.reshape(tf.tile(tf.range(g), [g]), (1, g, g)), 'float32')\n",
        "    c_y = tf.transpose(c_x, (0,2,1))\n",
        "    return tf.stack([tf.reshape(c_x, (-1, g*g)), tf.reshape(c_y, (-1, g*g))] , -1)\n",
        "\n",
        "c_grid = generate_yolo_grid(output_shape[0])\n",
        "\n",
        "\n",
        "def proccess_xy(y_true_raw):\n",
        "    y_true_xy = ((y_true_raw[..., 1:3]+1)/2 + c_grid)/output_shape[0]\n",
        "    y_true_wh = y_true_raw[..., 3:5]\n",
        "    y_true_conf = y_true_raw[..., :1]\n",
        "    return tf.concat([y_true_conf, y_true_xy, y_true_wh], -1)"
      ],
      "metadata": {
        "id": "QjLkV_VbNvuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prédiction des boundings boxes les plus probables"
      ],
      "metadata": {
        "id": "OBaMNgY8NyHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_bboxes(y, threshold=0.3):\n",
        "    y_xy = tf.cast(y, tf.float32)\n",
        "    y_xy = tf.expand_dims(y_xy, axis=0)\n",
        "    y_xy = proccess_xy(y_xy)[0]\n",
        "    #return y_xy\n",
        "    bboxes =  sorted(y_xy.numpy(), key=lambda x: x[0], reverse=True)\n",
        "    bboxes = np.array(bboxes)\n",
        "    result = bboxes[bboxes[:,0]>threshold]\n",
        "    if len(result)== 0:\n",
        "        return bboxes[[0]]\n",
        "    return result       \n"
      ],
      "metadata": {
        "id": "Kq54Q2T7NxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test sur image internet \n",
        "\n",
        "import time\n",
        "import cv2, urllib, json\n",
        "\n",
        "def show_img(img, model, threshold=0.2):\n",
        "    pred = model(np.array([img], dtype=np.float32))[0]\n",
        "    pred = transform_netout(pred)\n",
        "\n",
        "\n",
        "    bboxes_pred = pred_bboxes(pred, threshold)\n",
        "    plt.imshow(X_t[0]/255)\n",
        "    for bbox in bboxes_pred:\n",
        "        bbox = bbox[1:]\n",
        "        show_bounding_box(img/255, bbox)\n",
        "    \n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url) \n",
        "    img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    img = cv2.imdecode(img, -1)\n",
        "    img = cv2.resize(img, (256,256))\n",
        "    img = img[..., [2,1,0]]\n",
        "    return tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "\n",
        "# Exemple\n",
        "img = url_to_image(\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/iron-man-black-widow-marvel-1569327823.jpg\")\n",
        "show_img(img , model, 0.3)"
      ],
      "metadata": {
        "id": "YGeB9DmfN1m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# si mlauvais result \n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model('model_yolo', compile=False)"
      ],
      "metadata": {
        "id": "cac1hIoJN6-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sur webcam\n",
        "\n",
        "%matplotlib inline\n",
        "from IPython.display import HTML\n",
        "from PIL import Image\n",
        "import base64, io\n",
        "import numpy as np\n",
        "\n",
        "main_text = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "    canvas {\n",
        "        display: none;\n",
        "    }\n",
        "    </style>\n",
        "\n",
        "<video id=\"video\" width=\"320\" height=\"240\" autoplay></video>\n",
        "<button id=\"snap\">Snap Photo</button>\n",
        "<canvas id=\"canvas\" width=\"320\" height=\"240\"></canvas>\n",
        "\n",
        "<script>\n",
        "// Grab elements, create settings, etc.\n",
        "var video = document.getElementById('video');\n",
        "\n",
        "// Get access to the camera!\n",
        "if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "    // Not adding `{ audio: true }` since we only want video now\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {\n",
        "        //video.src = window.URL.createObjectURL(stream);\n",
        "        //video.play();\n",
        "        video.srcObject=stream;\n",
        "        video.play();\n",
        "    });\n",
        "}\n",
        "\n",
        "// Elements for taking the snapshot\n",
        "var canvas = document.getElementById('canvas');\n",
        "var context = canvas.getContext('2d');\n",
        "var video = document.getElementById('video');\n",
        "var image = canvas.toDataURL(\"image/png\");\n",
        "IPython.notebook.kernel.execute(\"image = '\" + image + \"'\")\n",
        "\n",
        "// Trigger photo take\n",
        "document.getElementById(\"snap\").addEventListener(\"click\", function() {\n",
        "\tcontext.drawImage(video, 0, 0, 320, 240);\n",
        "    var myCanvas = document.getElementById('canvas');\n",
        "    var image = myCanvas.toDataURL(\"image/png\");\n",
        "    IPython.notebook.kernel.execute(\"print('testing')\")\n",
        "    IPython.notebook.kernel.execute(\"imageWebCam = '\" + image + \"'\")\n",
        "});\n",
        "</script>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def show_bboxes_webcam(model):\n",
        "    img = np.array(Image.open(io.BytesIO(base64.b64decode(imageWebCam.split(',')[1]))))[:,:,0:3]\n",
        "    img = tf.image.resize(img, (256,256))\n",
        "    show_img(img, model)\n",
        "    \n",
        "HTML(main_text)"
      ],
      "metadata": {
        "id": "nUHVQb8sN9t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Une fois le bouton \"Snap Photo\" pressé, exécuter la cellule suivante."
      ],
      "metadata": {
        "id": "RScfYFPWOELE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNIQUEMENT EN LOCAL\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "# Load the cascade\n",
        "\n",
        "# To capture video from webcam. \n",
        "cap = cv2.VideoCapture(0)\n",
        "# To use a video file as input \n",
        "# cap = cv2.VideoCapture('filename.mp4')\n",
        "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
        "bottomLeftCornerOfText = (10,500)\n",
        "fontScale              = 1\n",
        "fontColor              = (0,255,0)\n",
        "lineType               = 2\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Read the frame\n",
        "    try :\n",
        "        _, img = cap.read()\n",
        "        # img = img[60:, 100:][:-60, :-100]\n",
        "        \n",
        "        img_resized = cv2.resize(img, (256, 256))\n",
        "        \n",
        "        prediction = model(np.array([img_resized[:,:,[2,1,0]]], dtype=np.float32))[0]\n",
        "        \n",
        "        prediction = transform_netout(prediction)\n",
        "        \n",
        "        bboxes = pred_bboxes(prediction, 0.05)\n",
        "        \n",
        "        # Convert to grayscale\n",
        "    #     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        # Detect the faces\n",
        "    #     faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "        # Draw the rectangle around each face\n",
        "        for c, x_m, y_m, w, h in bboxes:\n",
        "            x_m = x_m * img.shape[1]\n",
        "            y_m = y_m * img.shape[0]\n",
        "            w = w * img.shape[1]\n",
        "            h = h * img.shape[0]\n",
        "            cv2.rectangle(img, (int(x_m-w/2), int(y_m-h/2)), (int(x_m+w/2), int(y_m+h/2)), fontColor, 2)\n",
        "            cv2.putText(img, str(c)[:5], \n",
        "                        (int(x_m-w/2), int(y_m-h/2)+30), \n",
        "                        font, \n",
        "                        fontScale,\n",
        "                        fontColor,\n",
        "                        lineType)\n",
        "        # Display\n",
        "        \n",
        "        cv2.imshow('image', img)\n",
        "        # Stop if escape key is pressed\n",
        "        k = cv2.waitKey(30) & 0xff\n",
        "        if k==27:\n",
        "            break\n",
        "    except :\n",
        "        break\n",
        "# Release the VideoCapture object\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "StR9zeN6OE53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}